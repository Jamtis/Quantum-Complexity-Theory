\section{Introduction}
\label{Introduction}

Since Manin \cite{manin_1980} and Feynman \cite{feynman_1982} independently introduced the idea of a "universal quantum simulator" in 1980 and 1982 the proposal has become ever more popular due to the promise of an advantage in calculation efficiency over any classical computer; Preskill popularized the term quantum supremacy \cite{preskill_2012}.

To concretize this vague statement is to compare the respective classes of efficient computability for the quantum and the classical computer.
A mathematical computation model and a definition of efficient computability are therefore necessary in the quantum context.
Deutsch formulated the former \cite{deutsch_1985} as the \acl{QTM}; while Bernstein and Vazirani provided the latter \cite{bernstein_vazirani_1997} -- the \ac{BQP}.
This work follows the latter paper in large parts.

Although some relations to (classical) complexity classes have been established, many are still open.
One of them is--intuitively--whether quantum computers indeed yield any advantage over classical computers.

The field of quantum complexity theory tries to distinguish the quantum computation model from (classical) computation models more precisely.
One obvious application is the harvesting of the power of quantum computers to solve computation problems in general.
Another--only recently emerging--is the introduction of complexity theory into theoretical physics \cite{susskind_2016}.
However the application, the clarification of the border between quantum and classical computers is a crucial problem in computer science.

\section{Basics}

\subsection{\acl{QTM}}

Like the normal Turing machine represents a computation model of a classical mechanical machine, the \acl{QTM} models computation within quantum mechanics.
In some sense the \ac{QTM} is a generalization of the classical \ac{TM}, just as quantum mechanics is a generalization of classical mechanics.

In 1985 Deutsch \cite{deutsch_1985} provided an original definition of this computation model.
Bernstein and Vazirani use an only slightly modified version \cite{bernstein_vazirani_1997}.

\begin{definition}
\label{def:QTM}
\acl{QTM} \cite{bernstein_vazirani_1997}

Call $\mathbf{\tilde{C}}$ the set consisting of $\alpha\in\mathbf{C}$ such that there is a deterministic algorithm that computes the real and imaginary parts of $\alpha$ to within $2^{-n}$ in time polynomial in $n$.

A \ac{QTM} $M$ is defined by a triplet $(\Sigma, Q, \delta)$, where $\Sigma$ is a finite alphabet with an identified blank symbol $\#$, $Q$ is a finite set of states with an identified initial state $q_0$ and final state $q_\mathrm{f}\neq q_0$, and $\delta$, the quantum transition function, is a function
\begin{equation*}
    \delta
    :Q\times\Sigma
    \rightarrow
    \mathbf{\tilde{C}}^{\Sigma\times Q\times\{L,R\}}
    \ .
\end{equation*}
The \ac{QTM} has a two-way infinite tape of cells indexed by $\mathbf{Z}$ and a single read/write tape head that moves along the tape.
We define configurations, initial configurations, and final configurations exactly as for deterministic \acp{TM}.
\end{definition}

As usual, the number of tapes, the alphabet size and whether the tape head may rest in one step are irrelevant with regards to polynomial runtime.
Each \ac{QTM} describes a time evolution operator which represents the evolution (e.g. superposition of to new states) of the machines state in one time step.

A special circumstance in the quantum world is the issue of measurement -- an open philosophical question leading to different interpretations of quantum theory.
What it means to measure the (partial) state of a \ac{QTM} is to be handled pragmatically -- simply as a random variable with a certain probability distribution.

\acp{QTM} may have various properties that prove useful for the proofs in \cref{Relations}.

Strictly speaking, the mathematical model of the \ac{QTM} is too powerful to correctly mirror the computation power of physical quantum computers.
Quantum physics adheres to unitarity -- that is the preservation of euclidian length of a state after one application of the time evolution operator.
An other way of formulating unitarity is to say that the time evolution operator describes a rotation in the space of states -- and therefore preserving length.
\acp{QTM} exhibiting this property are called well-formed.
$\mathcal{S}$ denotes the space of states and is assume to be equal for all \ac{QTM} in the following.
\begin{definition}
Wellformedness (Definition 3.3 in \cite{bernstein_vazirani_1997})

A \ac{QTM} $M$ is well-formed iff for each $\phi\in\mathcal{S}$ follows
\begin{equation*}
    \norm{U_M\ket{\phi}}=\norm{\ket{\phi}}
    \ .
\end{equation*}
\end{definition}

Discrimination of \ac{QTM} requires a measure of distance between to \acp{QTM}.
In the following we given some results that establish a distance measure; ultimately to determine what it means for a \ac{QTM} to simulate another $\ac{QTM}$ within some margin of error.
We start from a constructivist point of view defining an initial measure and then deduce how this distance (error) propagates though the simulation process and how it alters the acceptance behaviour of the simulating \ac{QTM} with respect to the original one.

A measure arising from constructing a \ac{QTM} by its transition amplitudes is the so-called $\epsilon$-closeness.
\begin{definition}
$\epsilon$-Closeness (Definition 3.8 in \cite{bernstein_vazirani_1997})

We say that \acp{QTM} $M$ and $M'$ are $\epsilon$-close if they have the same state set and alphabet and if the difference between each pair of corresponding transition amplitudes has magnitude at most $\epsilon$.
Note that $M$ and $M'$ can be $\epsilon$-close even if one or both are not well formed.
\end{definition}
This measure proves useful when representing formal \ac{QTM} within a classical \ac{TM} where the transition amplitudes must be approximated to some degree; for example the amplitude $\frac{1}{3}$ is valid for a formal \ac{QTM} but requires a infinite amount of storage in a classical \ac{TM}.

\begin{theorem}
\label{th:bete}
Bounded-Error-Time-Evolution (Theorem 3.9 in \cite{bernstein_vazirani_1997})

If \acp{QTM} $M$ and $M'$ with alphabet $\Sigma$ and state set $Q$ are $\epsilon$-close, then the difference in their time evolutions has norm at most $2\cdot\vert\Sigma\vert\cdot\vert Q\vert\cdot\epsilon$.
Moreover, this statement holds even if one or both of the machines are not well-formed.
\\
More formally, let $U$ and $U'$ be the respective time evolution operator of $M$ and $M'$, then
\begin{equation}
    \norm{(U'-U)\ket{\phi}}
    \leq 2\cdot\vert\Sigma\vert\cdot\vert Q\vert\cdot\epsilon
\end{equation}
for any $\phi\in\mathcal{S}$.

\begin{proof}
From \cite{bernstein_vazirani_1997}.

Let \acp{QTM} $M$ and $M'$ with alphabet $\Sigma$ and state set $Q$ be given which are $\epsilon$-close. Let $U$ be the time evolution of $M$, and let $U'$ be the time evolution of $M'$.

Now, consider any unit length superposition of condigurations $\ket{\phi}=\sum_j\alpha_j\ket{c_j}$.
Then we can express the difference in the machines' operations on $\ket{\phi}$ as follows:
\begin{equation}
    (U-U')\ket{\phi}
    =\sum_j\left[\sum_{i\in P(j)}\left(\lambda_{i,j}-\lambda'_{i,j}\right)\alpha_i\right]\ket{\phi}
\end{equation}
where $P(j)$ is the set of $i$ such that configuration $c_i$ can lead to $c_j$ in a single step of $M$ or $M'$ and where $\lambda_{i,j}$ and $\lambda'_{i,j}$ are the amplitudes with which $c_i$ leads to $c_j$ in $M$ and $M'$.

Applying the triangle inequality and the fact that the square of the sum of $n$ reals is at most $n$ times the sum of their squares, we have
\begin{multline}
    \norm{(U-U')\ket{\phi}}^2
    =\sum_j\abs{\sum_{i\in P(j)}\left(\lambda_{i,j}-\lambda'_{i,j}\right)\alpha_i}^2
    \\
    \leq \sum_j2\abs{\Sigma}\abs{Q}\sum_{i\in P(j)}\abs{\left(\lambda_{i,j}-\lambda'_{i,j}\right)\alpha_i}^2
    \ .
\end{multline}
Then since $M$ and $M'$ are $\epsilon$-close, we have
\begin{multline}
    \sum_j2\abs{\Sigma}\abs{Q}\sum_{i\in P(j)}\abs{\left(\lambda_{i,j}-\lambda'_{i,j}\right)\alpha_i}^2
    =2\abs{\Sigma}\abs{Q}\sum_j\sum_{i\in P(j)}\abs{\lambda_{i,j}-\lambda'_{i,j}}^2\abs{\alpha_i}^2
    \\
    \leq 2\abs{\Sigma}\abs{Q}\epsilon^2\sum_j\sum_{i\in P(j)}\abs{\alpha_i}^2
\end{multline}
Finally since for any configuration $c_j$, there are at most $2\abs{\Sigma}\abs{Q}$ configurations that can lead to $c_j$ in a single step, we have
\begin{equation}
    2\abs{\Sigma}\abs{Q}\epsilon^2\sum_j\sum_{i\in P(j)}\abs{\alpha_i}^2
    \leq 4\abs{\Sigma}^2\abs{Q}^2\epsilon^2\sum_i\abs{\alpha_i}^2
    =4\abs{\Sigma}^2\abs{Q}^2\epsilon^2
\end{equation}
Therefore, for any unit length superposition $\ket{\phi}$
\begin{equation}
    \norm{(U-U')\ket{\phi}}^2
    \leq 2\abs{\Sigma}\abs{Q}\epsilon
    \ .
\end{equation}
\end{proof}
\end{theorem}
Informally, this means that the total error of one time evolution step (the distance between the states of the two \acp{QTM}) scales linearly with the maximal distance $\epsilon$ of the corresponding transition amplitudes.
We can--therefore--limit the overall state distance by requiring sufficient $\epsilon$-closeness.

Furthermore, the error (state distance) between unequal machines propagates through time.
A maximal time evolution error of $\kappa$ in one step results in a maximal distance of $((T\cdot\kappa)$ after $T$ steps.
This theorems shows that the error induced by $\epsilon$-close machines does not limit the runtime significantly.
The distance between the desired state $U^T\ket{\phi}$ and the approximation state ${U'}^T\ket{\phi}$ scales only linearly with runtime $T$.
\begin{theorem}
\label{th:adde}
Additive-Error-Propagation (simplified version; Theorem 3.7 in \cite{bernstein_vazirani_1997})

Let $T\geq0$ and $U$ and $U'$ be time evolution operators of \textbf{well-formed} \acp{QTM}.
The error induced by one time evolution operator $U'$ with regard to $U$ accumulates only additively over multiple time steps.

More formally, if $\norm{(U'-U)\ket{\phi}}\leq\kappa$, then
\begin{equation}
    \norm{\left({U'}^T-U^T\right)\ket{\phi}}\leq\kappa\cdot T
\end{equation}
for any $\phi\in\mathcal{S}$.

\begin{proof}
The proof in the original paper \cite{bernstein_vazirani_1997} has some technical issues and does not intuitively link in with the other theorems.
Therefore, we use a simplified but equally valid version of the proof.

First note that--because $U$ and $U'$ are unitary--applying $U'$ $a$ times $U'$ and $U$ $b$ times preserves length
\begin{equation}
\label{eq:addrotation}
    \kappa
    \geq\norm{(U'-U)\ket{\phi}}
    =\norm{\left(U'-U\right)\left({U'}^aU^b\right)\ket{\phi}}
    =\norm{\left({U'}^{a+1}U^b-{U'}^aU^{b+1}\right)\ket{\phi}}
\end{equation}
for any $a$ and $b$.
Also, we can write the desired (erroneous) operator as a telescope sum
\begin{equation}
    {U'}^T-U^T
    =\sum_{j=0}^{T-1}\left[{U'}^{j+1}U^{T-j-1}-{U'}^jU^{T-j}\right]
    \ .
\end{equation}
Now, combining this sum with \cref{eq:addrotation} and the triangle inequality results in
\begin{multline}
    \norm{\left({U'}^T-U^T\right)\ket{\phi}}
    =\norm{\sum_{j=0}^{T-1}\left[{U'}^{j+1}U^{T-j-1}-{U'}^jU^{T-j}\right]\ket{\phi}}
    \\
    \leq\sum_{j=0}^{T-1}\norm{\left[{U'}^{j+1}U^{T-j-1}-{U'}^jU^{T-j}\right]\ket{\phi}}
    \leq\sum_{j=0}^{T-1}\kappa
    =\kappa\cdot T
\end{multline}
with $a=j$ and $b=T-j-1$ respectively.

Note that this theorem heavily relies on the unitarity of $U$ and $U'$.
\end{proof}
\end{theorem}

\begin{corollary}
Summarizing the previous results -- we now know that the states of two $\epsilon$-close \acp{QTM} $M$ and $M'$ after $T$ steps have a maximal distance of $2\cdot\vert\Sigma\vert\cdot\vert Q\vert\cdot\epsilon\cdot T$.
\end{corollary}

The final link between $\epsilon$-closeness and simulation of \acp{QTM} is how distance of states forms the difference between the output distributions.
To connect the distance of two (final) states to the output distributions, we use the following lemma.
\begin{lemma}
\label{lemma:statedist}
State-Distribution (Lemma 3.6 in \cite{bernstein_vazirani_1997})

Let $\phi,\psi\in\mathcal{S}$ (two states from the space of states) such that $\norm{\ket{\phi}}=\norm{\ket{\psi}}=1$, and $\norm{\ket{\phi}-\ket{\psi}}\leq d\leq 2$. Then the total variation distance between the probability distributions resulting from measurements of $\phi$ and $\psi$ is at most $2d$ ($4d$ in the original paper); formally
\begin{equation}
    \vert\mathcal{D}_\phi-\mathcal{D}_\psi\vert\leq 2d
    \ .
\end{equation}

\begin{proof}
Modified from \cite{bernstein_vazirani_1997}.

First, consider $\ket{\phi}=\sum_i\alpha_i\ket{i}$ and $\ket{\psi}=\sum_i\beta_i\ket{i}$ and 
define the distance state
\begin{equation}
    \ket{\pi}
    :=\ket{\phi}-\ket{\psi}
    =\sum_i\left(\alpha_i-\beta_i\right)\ket{i}
    =\sum_i\gamma_i\ket{i}
\end{equation}
where $\abs{\alpha_i}^2$ and $\abs{\beta}^2$ are the probabilities for $i$ in $\ket{\phi}$ and $\ket{\psi}$ respectively.
Then rewrite
\begin{multline}
    \abs{\alpha_i}^2
    =\alpha^*_i\alpha_i
    =\left(\gamma^*_i+\beta^*_i\right)\left(\gamma_i+\beta_i\right)
    \\
    =\gamma^*_i\gamma_i+\gamma^*_i\beta_i+\beta^*_i\gamma+\beta^*_i\beta_i
    =\abs{\gamma_i}^2+\gamma^*_i\beta_i+\beta^*_i\gamma+\abs{\beta_i}^2
\end{multline}
and plug it in the definition of the total variation distance
\begin{multline}
    \abs{\mathcal{D}_\phi-\mathcal{D}_\psi}
    =\frac{1}{2}\sum_i\abs{\abs{\alpha_i}^2-\abs{\beta_i}^2}
    =\frac{1}{2}\sum_i\abs{\abs{\gamma_i}^2+\gamma^*_i\beta_i+\beta^*_i\gamma+\abs{\beta_i}^2-\abs{\beta_i}^2}
    \\
    =\frac{1}{2}\sum_i\abs{\abs{\gamma_i}^2+\gamma^*_i\beta_i+\beta^*_i\gamma}
    \overset{(1)}{\leq}\frac{1}{2}\sum_i\left(\abs{\gamma_i}^2+\abs{\gamma^*_i\beta_i}+\abs{\beta^*_i\gamma_i}\right)
    \\
    \overset{(2)}{\leq}\frac{1}{2}\left[\left(\sum_i\abs{\gamma_i}^2\right)+\left(\norm{\gamma^*}\norm{\beta}+\norm{\beta^*}\norm{\gamma}\right)\right]
    \overset{(3)}{\leq}\frac{1}{2}\left(d^2+2d\right)
    \leq 2d
\end{multline}
where $(1)$ follows from the triangle inequality, $(2)$ from the Cauchy-Schwarz inequality and $(3)$ from the maximal distance of $\ket{\phi}$ and $\ket{\psi}$.
\end{proof}
\end{lemma}

Finally, we define what it means to simulate a \ac{QTM}.
\begin{definition}
Accuracy (Definition 3.5 in \cite{bernstein_vazirani_1997})

We say that \ac{QTM} $M'$ simulates $M$ with slowdown $f$ with accuracy $a$ if the following holds: let $\mathcal{D}$ be a distribution such that observing $M$ on input $x$ after $T$ steps produces a sample from $\mathcal{D}$. Let $\mathcal{D}'$ be distribution such that observing $M'$ on input $x$ after $f(T)$ steps produces a sample from $\mathcal{D}'$. Then we say that $M'$ simulates $M$ with accuracy $a$ if $\vert\mathcal{D}-\mathcal{D}'\vert\leq a$.
\end{definition}
In light of this definition, we can link the total variation distance to the distance in states after $T$ time steps (\cref{lemma:statedist}), to the distance in one single time step (\cref{th:adde}), and finally to the distance of two corresponding transition amplitudes (\cref{th:bete}).

\begin{corollary}
\label{col:etod}
A \ac{QTM} $M'$ simulates another \ac{QTM} $M$ with accuracy $4\cdot\vert\Sigma\vert\cdot\vert Q\vert\cdot\epsilon\cdot T$ if $M$ and $M'$ are $\epsilon$-close.
\end{corollary}



\subsection{\acl{BQP}}

To examine the capabilities of \acp{QTM} not just in terms of effectiveness but also efficiency the class of "efficiently decidable" problems must be defined.
With a suited interpretation of the \ac{QTM}--that is with the same interface as a classical \ac{TM} (input as a $n$-bit string, output one bit)-- the definition of "efficiently decidable" class follows canonically from the classical analog $\BPP$.

\begin{definition}
\acf{BQP}

The complexity class $\BQP$ may be defined as the class of languages for which there exists a \ac{QTM} $Q$ such that $Q$ accepts all $x\in L$ and rejects all $x\not\in L$ with at least probability of $\frac{2}{3}$; or more formally

\begin{equation*}
    L\in\BQP
    \Leftrightarrow
    \exists\mathrm{QTM}\ Q:
    \begin{cases}
    & \forall x\in L:\Pr{Q(x)=1}\geq\frac{2}{3}
    \\
    \wedge
    & \forall x\not\in L:\Pr{Q(x)=0}\geq\frac{2}{3}
    \end{cases}
    \ .
\end{equation*}
As usual, the constant acceptance probability of $\frac{2}{3}$ is arbitrary; even $\frac{1}{2}+\Omega(\abs{x}^{-c})$ for any $c>0$ suffices \cite{arora_barak_2016}.

\end{definition}

\section{Relation}
\label{Relations}

\subsection{$\BQP$ vs $\BPP$}

Because a \ac{QTM} is a generalization of the classical \ac{TM} it is intuitive that $\BPP\subseteq\BQP$.
@TODO: Include formal proof or refer to it

On the other hand, $\BQP\subseteq\BPP$ is neither known and nor guessed to be true.
In fact, the opposite conjecture $\BPP\subset\BQP$ is the driving force behind the recent interest in quantum computing as it says that quantum computers yield a superpolynomial advantage over classical computers for \textbf{some} problems.

\subsection{$\BQP$ vs $\EXP$}

Naturally--from the desire to pin down the borders of quantum computing--the question arises: what is the upper limit of the efficiency advantage of \acp{QTM}?
One upper limit is $\BQP\subseteq\EXP$, in other words this means that a language that a quantum computer can decide in polynomial time a classical computer can decide in exponential time.
Inversely a quantum computer may in principle only ever yield a exponential speedup over any classical computer.
Even Shor's algorithm \cite{shor_1997} does only exhibit a superpolynomial but subexponential speedup over the general number field sieve (the best classical algorithm for integer factorization to date).

Also it means that the progress and therefore the state of a (efficient) \ac{QTM} can be simulated purely classically.
The proof of this upper limit showcases the technique of simulating a \ac{QTM} classically with sufficient accuracy so that the difference in output are negligible.

\begin{theorem}
\label{th:bqpexp}
$\BQP\subseteq\EXP$ (modified from Theorem 8.4 in \cite{bernstein_vazirani_1997})

\begin{proof}
The idea of the proof is to approximate the complex transition amplitudes of the given \ac{QTM} with sufficiently many bits in a classical \ac{TM} so that the difference in the resulting distributions is negligible.

Let $M=(\Sigma, Q, \delta)$ be a $\BQP$ machine with running time $T(\abs{x})\in\mathrm{poly}(\abs{x})$.
Further assume the output of $M$ is binary -- its output distribution is over $\{0,1\}$.
So, we need an approximated version of $M$ called $M'$.
Furthermore, $M'$ must accept the exact same language $L$ as $M$.
Let $\chi:L\to\{0,1\}$ be the indicator function of $L$.
Then, for some $c'>0$
\begin{equation}
\label{eq:samelang}
    \Pr{M'(x)=\chi(x)}
    \geq\frac{1}{2}+\zeta'(\abs{x})
    \in\frac{1}{2}+\Omega\left(\abs{x}^{-c'}\right)
\end{equation}
is sufficient for $M'$ to decide $L$.
Analogously, such a $\zeta$ and $c$ exists for $M$.
In the following, we give a $\zeta'$ and $c'$ that satisfies \cref{eq:samelang}.
Now assume an accuracy (total variation distance) between $M$ and $M'$ of at most $a$.
Applying the definition of the total variation distance gives
\begin{multline}
    a
    \geq\abs{\mathcal{D}-\mathcal{D}'}
    \\
    =\frac{1}{2}\left[\abs{\Pr{M(x)=0)}-\Pr{M'(x)=0}}+\abs{\Pr{M(x)=1}-\Pr{M'(x)=1}}\right]
    \ .
\end{multline}
In case $\Pr{M(x)=b)}\leq\Pr{M'(x)=b}$ \cref{eq:samelang} is trivially satisfied for any $b\in\{0,1\}$ with $\zeta'=\zeta$ and $c'=c$.
In case $\Pr{M(x)=b)}>\Pr{M'(x)=b}$ consider the following bound
\begin{multline}
    2a
    \geq 2a-\abs{\Pr{M(x)=1-b}-\Pr{M'(x)=1-b}}
    \\
    \geq\abs{\Pr{M(x)=b}-\Pr{M'(x)=b}}
    =\Pr{M(x)=b}-\Pr{M'(x)=b}
    \ .
\end{multline}
which results from multiplying the previous inequality with $2$.
Rearranging the terms gives
\begin{equation}
    \Pr{M'(x)=b}
    \geq \Pr{M(x)=b}-2a
    =\frac{1}{2}+\zeta(\abs{x})-2a
    \overset{\eqref{eq:samelang}}{\in}\frac{1}{2}+\Omega(\abs{x}^{-c'})
\end{equation}
which means that if $a$ is small enough, then \cref{eq:samelang} is satisfied.
Somewhat arbitrarily, choosing $a:=\frac{1}{2}\zeta(\abs{x})\in\frac{1}{2}+\Omega(\abs{x}^{-c})$ results in
\begin{equation}
    \Pr{M'(x)=b}
    \geq\frac{1}{2}+\frac{1}{2}\zeta(\abs{x})
    \in\frac{1}{2}+\Omega(\abs{x}^{-c})
\end{equation}
and thus \cref{eq:samelang} is satisfied with $\zeta'=\frac{1}{2}\zeta$ and $c'=c$.
\\
So in both case there exists a $\zeta'=\frac{1}{2}\zeta$ and a $c'=c>0$ such that the probability of $M'$ (accepting and rejecting) meets the requirements for $M'$ to be a $\BQP$ machine.

Furthermore, we want to determine the necessary $\epsilon$-closeness for the required accuracy $a=\frac{1}{2}\zeta(\abs{x})$.
Recall \cref{col:etod}.
Then the required closeness for $M'$ to simulate $M$ in $T(\abs{x})$ steps with sufficient accuracy $a$--for $M'$ to be a $\BQP$ machine--is
\begin{equation}
    a
    =4\cdot\abs{\Sigma}\cdot\abs{Q}\cdot\epsilon\cdot T(\abs{x})
    \overset{!}{=}\frac{1}{2}\zeta(\abs{x})
    \Rightarrow
    \epsilon
    =\frac{\zeta(\abs{x})}{8\cdot\abs{\Sigma}\cdot\abs{Q}\cdot T(\abs{x})}
    \ .
\end{equation}
Because $\frac{1}{\zeta(\abs{x})}$ and $T(\abs{x})$ are both polynomials in $\abs{x}$ the necessary precision of $\epsilon$--that is the bits required to represent $\epsilon$--is $\log_2\left(\frac{1}{\epsilon}\right)\in\Theta\left(\log(\abs{x})\right)$.

Informally, this means that a "discretized" version of $M$ can be used to decided the same language that $M$ decides.
This version $M'$ can be represented by finite many bits -- as the amount of bits necessary to accurately describe the transition amplitudes is only logarithmic in input size $\abs{x}$.

Now we lay out the way a deterministic \ac{TM} $M^*$ can simulate $M'$.
Consider the configuration graph $G$ of $M'$; the runtime of $M'$ $T(\abs{x})$ is also the length of all paths in $G$.
However, there may be exponentially many paths.
$M*$ calculates the amplitudes of each path by multiplying the transition amplitudes along a path.
The amplitudes can only be calculated by $M^*$ because of the discretized nature of $M'$, thus the required bits to represent a path amplitude are in $\mathcal{O}\left(\log_2(\abs{x})\cdot T(\abs{x})\right)$ -- still only polynomial in $\abs{x}$.
Afterwards $M^*$ sums up all squared magnitudes of paths which lead to accepting configurations.
If the sum exceeds $\frac{1}{2}+\zeta'(\abs{x})$, then $M^*$ outputs $1$ and $0$ else.
The overall runtime is exponential due to the exponential size of $G$.
\end{proof}
\end{theorem}

\subsection{$\BQP$ vs $\PSPACE$}
An improved upper bound of $\BQP$ is $\BQP\subseteq\PSPACE$.

\begin{theorem}
\label{th:bqppspace}
$\BQP\subseteq\PSPACE$

\begin{proof}
This proof is analog to $\BQP\subseteq\EXP$ inspired by the original proof in \cite{bernstein_vazirani_1997}.

Analogously to \cref{th:bqpexp} we use a discretized version $M'$ of $M$ which we want to simulate using a deterministic \ac{TM} $D$ in $\PSPACE$.
The problem--with the strategy of first calculating the amplitudes of all paths and the summing them up--is obviously that there are exponentially many path and therefore a $\PSPACE$ machine cannot save all path amplitudes.

The simple solution to this problem is to use a depth-first search over the configuration graph $G$ and calculate the acceptance probability--that is the squared magnitudes of all paths leading to accepting configurations--as a running sum.
Because a depth-first search over a graph with distance $T(\abs{x})$ requires only space $\Omega(T(\abs{x}))$ $D$ is indeed a $\PSPACE$ machine -- although the calculation may require exponential time.
Also, the number of required bits for the acceptance probability grows only logarithmically in the (exponential) number of contributing paths.
The overall number of required bits is again polynomial in $\abs{x}$.
\end{proof}
\end{theorem}
This result is particularly interesting because even $\P\overset{?}{=}\PSPACE$ is still an open question.
A result like $\BPP\subset\BQP$ or $\BQP\subset\PSPACE$ would already separate $\P$ from $\PSPACE$; showing the difficulty of the proofs of these statements.

\subsection{$\BQP$ vs $\NP$ and $\NPC$}
To further pin down the boundaries of $\BQP$ it might be useful to compare it to other well-known complexity classes such as $\NP$ -- also incorporating as special computation model.
However, just as no relation between $\NP$ and $\BPP$ could yet be established, no relation between $\NP$ and $\BQP$ could either.

Note that these consideration only make sense given $\P\neq\NP$; otherwise the question reduces to $\P\overset{?}{\neq}\BQP$.

First, we want to look at the implications of possible relations and then compare those to whether they are generally assumed to be true.
The first interesting question might be whether quantum computer can be used to solve $\NPC$ problems; formally
\begin{equation*}
    \NPC\overset{?}{\subseteq}\BQP
    \ .
\end{equation*}
If quantum computers could solve $\NPC$ problems, then they certainly could solve all $\NP$ problems
\begin{equation}
    \NPC\subseteq\BQP
    \Rightarrow
    \NP\subseteq\BQP
    \ .
\end{equation}
To date, no $\BQP$ algorithm is known to solve a $\NPC$ problem.
In fact it is the default conjecture that $\NPC\not\subseteq\BQP$ which implies $\NPC\cap\BQP=\emptyset$.
This is because a quantum computer could use a $\NPC$ problem inside $\BQP$ to solve all $\NPC$ problems via polynomial reduction.

\begin{figure}[t!]
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]{"../presentation/images/ContextofBQP".pdf}
\caption{Default conjecture of $\BQP$ in the context of classical complexity classes}
\label{fig:overview}
\end{figure}

The opposite inclusion
\begin{equation*}
    \BQP\overset{?}{\subseteq}\NP
\end{equation*}
poses the question if the nondeterministic computation model is more powerful the quantum model.
Ladner's theorem \cite{ladner_1975} tells us that given $\P\neq\NP$ the class of $\NP$ problems neither in $\P$ nor in $\NP$
\begin{equation*}
    \NPI:=\NP\setminus(\P\cup\NPC)
\end{equation*}
is not empty.
A candidate for such a problem is \ac{IF} (strictly not a decision problem).
Because multiplication is fast \ac{IF} is obviously in $\NP$ and because of Shor's algorithm \ac{IF} is also in $\BQP$ \cite{shor_1997}.
The runtime of the currently best algorithms for \ac{IF} may give a hint as to why \ac{IF} is presumably in $\NPI$.
Number field sieve algorithms have superpolynomial but subexponential runtime \cite{pomerance_1996}.
However, $\NPC$ problems cannot have subexponential runtime unless the \textbf{Exponential Time Hypothesis} is false \cite{impagliazzo_paturi_1999}.
Also, if \ac{IF} was in $\P$, then a polynomial algorithm for \ac{IF} would exists.
Thus, \ac{IF} seems to be in the intersection $(\NP\cap\BQP)\setminus\P$.

To show that $\BQP\not\subseteq\NP$, it is natural to look at $\BQP$-complete problems ($\BQPC$) as they are the least likely to be contained in $\NP$.
Although there are known $\BQPC$ problems \cite{pawel_shengyu_2006}, non are known to be in $\NP$.
In contrast, any strict inclusion $\BQP\subset\NP$ or $\NP\subset\BQP$ would already introduce a separation between $\P$ and $\PSPACE$.

To summarize, the default conjecture is that problems like \ac{IF} lie at the intersection of $\NP$ and $\BQP$ and both classes have their respective complete subsets outside of each other; compare \cref{fig:overview}.
Much work is to be done in this area, not only as a mathematical exercise but foremost to increase the understanding of the underlying computational model.

\section{Summary}
\label{Summary}

The quantum computation model has the inherent advantage--over other models like nondeterminism--that it can in principle be realized because it mirrors the rules of physics.
Although the model is mathematical accessible and the class of efficient computation $\BQP$ with this model is well-defined a formal proof of the quantum supremacy $\BPP\subset\BQP$ is yet to be produced.

Basic bounds like $\BQP\subseteq\PSPACE$ have been shown but most relations to relevant complexity classes are still open.
A critical reason for the difficulty of separating $\BQP$ from other classes lies in the fact that it would also imply the solution to major complexity-theoretical problems like $\P\overset{?}{\neq}\NP$ or $\P\overset{?}{=}\PSPACE$.
Especially the relation of $\BQP$ and $\NP$ is of particular interest because both classes are the efficient variants of their respective computational models.

An more practical aspect of quantum complexity theory is the search for and construction of efficient quantum algorithms for $\BQPC$ problems.
These algorithms will harvest the full (potential) quantum advantage and as a byproduct help to speed up the solution of $\NPC$ problems to the greatest degree.

The rigorous establishment of relations between quantum and classical complexity is crucial, not only because the canon of knowledge on this field is small in comparison to the projected technological progress but to ensure future investment in the field of quantum complexity and--maybe most importantly--the information it provides about the fundamental mechanisms governing the behaviour of physics.